{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tqdm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.24 seconds.\n",
      "Convergence after 10 epochs took 0.25 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (dim,1) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w=np.zeros_like(dim)\n",
    "    b=0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7I6uWBRsKc4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    sz=1/(1+np.exp(-z))\n",
    "    return sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    sum=0\n",
    "    for i in range(0,len(y_true)):\n",
    "        sum=sum+((y_true[i]*math.log10(y_pred[i]+10**-20))+((1-y_true[i])*math.log10(1-y_pred[i]+10**-20)))\n",
    "    loss=-1*sum/len(y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "  loss=logloss(true,pred)\n",
    "  assert(loss==0.07644900402910389)\n",
    "  return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = np.dot(x,(y-sigmoid(np.dot(np.transpose(w),x) + b))) - np.dot(w,(alpha/N))\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.sum(grad_dw)==2.613689585)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    "def gradient_db(x,y,w,b):\n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "    db=(y-sigmoid(np.dot(w,x)+b))\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(w,b,x):\n",
    "    pp=[]\n",
    "    for i in range(0,len(x)):\n",
    "        z=np.dot(np.transpose(w),x[i])+b\n",
    "        pp.append(sigmoid(z))\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    #implement the code as follows\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    # for every epoch\n",
    "        # for every data point(X_train,y_train)\n",
    "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "           #compute gradient w.r.to b (call the gradient_db() function)\n",
    "           #update w, b\n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the train loss values in a list\n",
    "        # predict the output of x_test[for all data points in X_test] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the test loss values in a list\n",
    "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "    tr_loss=[]\n",
    "    te_loss=[]\n",
    "    epoch_list=[]\n",
    "    best_w=None\n",
    "    best_b=None\n",
    "    w,b=initialize_weights(X_train[0])\n",
    "    ytr_pred=predict_proba(w,b,X_train)\n",
    "    tr_loss.append(logloss(y_train,ytr_pred))\n",
    "    yte_pred=predict_proba(w,b,X_test)\n",
    "    te_loss.append(logloss(y_test,yte_pred))\n",
    "    epoch_list.append(0)\n",
    "    print('epoch : {} , loss : {}'.format(0,logloss(y_train,ytr_pred)))\n",
    "    for i in range(1,epochs+1): \n",
    "        for k in range(0,len(X_train)): \n",
    "            bw=w+(eta0*gradient_dw(X_train[k],y_train[k],w,b,alpha,len(X_train)))\n",
    "            bb=b+(eta0*gradient_db(X_train[k],y_train[k],w,b))\n",
    "            w=bw\n",
    "            b=bb\n",
    "        ytr_pred=predict_proba(w,b,X_train)\n",
    "        ll=logloss(y_train,ytr_pred)\n",
    "        print('epoch : {} , loss : {}'.format(i,ll))\n",
    "        tr_loss.append(ll)\n",
    "        yte_pred=predict_proba(w,b,X_test)\n",
    "        te_loss.append(logloss(y_test,yte_pred))\n",
    "        epoch_list.append(i)\n",
    "    return w,b,tr_loss,te_loss,epoch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , loss : 0.3010299956640568\n",
      "epoch : 1 , loss : 0.17545748442854608\n",
      "epoch : 2 , loss : 0.16867157050333045\n",
      "epoch : 3 , loss : 0.1663916799246292\n",
      "epoch : 4 , loss : 0.16536827537403162\n",
      "epoch : 5 , loss : 0.16485707459547083\n",
      "epoch : 6 , loss : 0.1645882001292827\n",
      "epoch : 7 , loss : 0.16444271323364382\n",
      "epoch : 8 , loss : 0.16436263615826985\n",
      "epoch : 9 , loss : 0.16431806946667746\n",
      "epoch : 10 , loss : 0.1642930737413251\n",
      "--------------------------------------------------------------------------------\n",
      "w is : [-0.42320236  0.19097504 -0.14588903  0.33813461 -0.21204107  0.56528021\n",
      " -0.44537758 -0.09169276  0.21798654  0.16980147  0.19524869  0.00226123\n",
      " -0.0778474   0.33881857  0.02215503]\n",
      "b is : -0.850591279771658\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=10\n",
    "w,b,tr_loss,te_loss,epl=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)\n",
    "print('-'*80)\n",
    "print('w is : {}'.format(w))\n",
    "print('b is : {}'.format(b))\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00016455  0.00549939  0.00270133 -0.00330946 -0.00385437  0.00511442\n",
      "   0.00704724  0.00239537  0.00871335 -0.01103979 -0.00180322 -0.00195793\n",
      "   0.0017563   0.00029055 -0.00051218]]\n",
      "[0.00254702]\n"
     ]
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept15\n",
    "print(w-clf.coef_)\n",
    "print(b-clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.plot(epl,tr_loss,label='Train-loss')\n",
    "plt.plot(epl,te_loss,label='Test-loss')\n",
    "plt.legend(loc='center left',bbox_to_anchor=(1.0,0.5))\n",
    "plt.title('Epoch vs Train and Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUN8puFoEZtU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9553333333333334\n",
      "0.95288\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
